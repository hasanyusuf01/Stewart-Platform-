{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oPSy3VPHL5Uq"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datetime import datetime\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "targetsize =(224,224)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yFFakdIfNEEZ"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def euler_to_quaternion(roll, pitch, yaw):\n",
    "    # Convert degrees to radians\n",
    "    roll = math.radians(roll)\n",
    "    pitch = math.radians(pitch)\n",
    "    yaw = math.radians(yaw)\n",
    "\n",
    "    cy = math.cos(yaw * 0.5)\n",
    "    sy = math.sin(yaw * 0.5)\n",
    "    cp = math.cos(pitch * 0.5)\n",
    "    sp = math.sin(pitch * 0.5)\n",
    "    cr = math.cos(roll * 0.5)\n",
    "    sr = math.sin(roll * 0.5)\n",
    "\n",
    "    w = cr * cp * cy + sr * sp * sy\n",
    "    x = sr * cp * cy - cr * sp * sy\n",
    "    y = cr * sp * cy + sr * cp * sy\n",
    "    z = cr * cp * sy - sr * sp * cy\n",
    "\n",
    "    return w, x, y, z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "  def preprocess_input_img(test_image_path):\n",
    "    '''\n",
    "    This function takes the path to the input test image\n",
    "    and returns a preprocessed image (which can be used as a input to the model)\n",
    "    (Input): Single test image path\n",
    "    (Output): Preprocessed image\n",
    "    '''\n",
    "\n",
    "    # Read the original test image\n",
    "    orig_sample_test_img = cv2.cvtColor(cv2.imread(test_image_path), cv2.COLOR_BGR2RGB)\n",
    "    x = 50\n",
    "    y = 0\n",
    "    width = 200\n",
    "    height = 200\n",
    "#     print(\"preprocess input done\")\n",
    "    if orig_sample_test_img is None :\n",
    "            print(\"Failed to load images at preprocess\")\n",
    "            return None\n",
    "# Crop the image\n",
    "    orig_sample_test_img = orig_sample_test_img[y:y+height, x:x+width]\n",
    "    # Convert image to gray scale\n",
    "    gray_sample_test_img = cv2.cvtColor(orig_sample_test_img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Resizing image to desired input size\n",
    "    gray_resized_test_img = cv2.resize(gray_sample_test_img, targetsize,\n",
    "                        interpolation = cv2.INTER_AREA)   # To shrink an image\n",
    "\n",
    "    # Remove blemishes from image (if any)\n",
    "    (thresh, black_n_white_sample_img) = cv2.threshold(gray_resized_test_img, 70,255, cv2.THRESH_BINARY_INV)\n",
    "#     black_n_white_sample_img =cv2.GaussianBlur(black_n_white_sample_img , (3, 3), 0)\n",
    "    black_n_white_sample_img= cv2.dilate(black_n_white_sample_img, kernel, iterations=1)\n",
    "\n",
    "    _, black_n_white_sample_img = cv2.threshold(black_n_white_sample_img, 50, 255, cv2.THRESH_BINARY)\n",
    "    black_n_white_sample_img = black_n_white_sample_img/255\n",
    "    return orig_sample_test_img, black_n_white_sample_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_image(image_path, target_size=targetsize):\n",
    "    try:\n",
    "        _,img = preprocess_input_img(image_path)\n",
    "        transform = transforms.Compose([\n",
    "#         transforms.Resize(target_size),\n",
    "        transforms.ToTensor(),\n",
    "#         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ])\n",
    "        img = transform(img)\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {image_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "V2SCe0hDNeaV",
    "outputId": "02ea31cc-a3e8-4b9e-da02-1f2821ca4e52"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, main_folder, target_size=(25, 285), step_size=10):\n",
    "        self.main_folder = main_folder\n",
    "        self.target_size = target_size\n",
    "        self.step_size = step_size\n",
    "        self.data = []\n",
    "\n",
    "        for subdir, _, files in os.walk(main_folder):\n",
    "#             print(subdir, _)\n",
    "            if 'image_data.csv' in files:\n",
    "                csv_path = os.path.join(subdir, 'image_data.csv')\n",
    "                df = pd.read_csv(csv_path)\n",
    "                target_image_path = os.path.join(subdir, 'target.jpg')\n",
    "                for _, row in df.iterrows():\n",
    "                    X2_image_path = os.path.join(subdir, row['Image_Name'])\n",
    "                    self.data.append((target_image_path, X2_image_path, row['x'], row['y']))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        target_image_path, X2_image_path, x, y = self.data[idx]\n",
    "        \n",
    "        # Debugging print statements\n",
    "#         print(f\"Loading target image from: {target_image_path}\")\n",
    "#         print(f\"Loading X2 image from: {X2_image_path}\")\n",
    "        \n",
    "        target_image = load_image(target_image_path, self.target_size)\n",
    "        X2_image = load_image(X2_image_path, self.target_size)\n",
    "\n",
    "        # Check if load_image returns None\n",
    "        if target_image is None or X2_image is None:\n",
    "            print(f\"Failed to load images: {target_image_path}, {X2_image_path}\")\n",
    "            return None\n",
    "\n",
    "        # Convert roll, pitch, yaw to quaternion\n",
    "#         roll *= self.step_size\n",
    "#         pitch *= self.step_size\n",
    "#         yaw *= self.step_size\n",
    "#         w, p, q, r = euler_to_quaternion(roll, pitch, yaw)\n",
    "        poses = torch.tensor([x, y], dtype=torch.float32)\n",
    "        return (target_image, X2_image), poses\n",
    "\n",
    "\n",
    "# Initialize dataset and dataloaders\n",
    "main_folder = '/workspace/processed/'  # Replace with your main folder path\n",
    "dataset = CustomDataset(main_folder)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NVrCGU9jNkJb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PoseNet(\n",
       "  (pre_layers): Sequential(\n",
       "    (0): Conv2d(1, 8, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Conv2d(8, 16, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(16, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "    (4): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1.0)\n",
       "    (6): Conv2d(64, 128, kernel_size=(2, 2), stride=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(128, 192, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1.0)\n",
       "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (lastlayers): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Dropout(p=0.5, inplace=False)\n",
       "    (7): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): Dropout(p=0.5, inplace=False)\n",
       "    (10): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Dropout(p=0.5, inplace=False)\n",
       "    (13): Linear(in_features=32, out_features=16, bias=True)\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): Dropout(p=0.5, inplace=False)\n",
       "    (16): Linear(in_features=16, out_features=8, bias=True)\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): Dropout(p=0.5, inplace=False)\n",
       "    (19): Linear(in_features=8, out_features=2, bias=True)\n",
       "    (20): Tanh()\n",
       "  )\n",
       "  (a3): InceptionV1(\n",
       "    (b1): Sequential(\n",
       "      (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (b2): Sequential(\n",
       "      (0): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (b3): Sequential(\n",
       "      (0): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (b4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (b3): InceptionV1(\n",
       "    (b1): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (b2): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (b3): Sequential(\n",
       "      (0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(32, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (b4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (max_pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (a4): InceptionV1(\n",
       "    (b1): Sequential(\n",
       "      (0): Conv2d(960, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (b2): Sequential(\n",
       "      (0): Conv2d(960, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (b3): Sequential(\n",
       "      (0): Conv2d(960, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(16, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (b4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(960, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (b4): InceptionV1(\n",
       "    (b1): Sequential(\n",
       "      (0): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (b2): Sequential(\n",
       "      (0): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (b3): Sequential(\n",
       "      (0): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (b4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (c4): InceptionV1(\n",
       "    (b1): Sequential(\n",
       "      (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (b2): Sequential(\n",
       "      (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (b3): Sequential(\n",
       "      (0): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (b4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (d4): InceptionV1(\n",
       "    (b1): Sequential(\n",
       "      (0): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (b2): Sequential(\n",
       "      (0): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (b3): Sequential(\n",
       "      (0): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (b4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (e4): InceptionV1(\n",
       "    (b1): Sequential(\n",
       "      (0): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (b2): Sequential(\n",
       "      (0): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (b3): Sequential(\n",
       "      (0): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (b4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (a5): InceptionV1(\n",
       "    (b1): Sequential(\n",
       "      (0): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (b2): Sequential(\n",
       "      (0): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (b3): Sequential(\n",
       "      (0): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (b4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (b5): InceptionV1(\n",
       "    (b1): Sequential(\n",
       "      (0): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (b2): Sequential(\n",
       "      (0): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (b3): Sequential(\n",
       "      (0): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(48, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (b4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "      (1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avg_pool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (avg_pool5x5): AvgPool2d(kernel_size=5, stride=3, padding=0)\n",
       "  (conv1x1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (conv1x12): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (fc): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "  (fc2048): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "  (dropout5): Dropout(p=0.5, inplace=False)\n",
       "  (dropout7): Dropout(p=0.7, inplace=False)\n",
       "  (relu): ReLU()\n",
       "  (cls_fc_pose_xyz): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "  (cls_fc_pose_xyz_1024): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (tanh): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "__all__ = ['PoseNet', 'posenet_v1', 'PoseLoss']\n",
    "\n",
    "class InceptionV1(nn.Module):\n",
    "    def __init__(self, in_channels, n1x1, n3x3red, n3x3, n5x5red, n5x5, pool_planes):\n",
    "        super(InceptionV1, self).__init__()\n",
    "        # 1x1 conv branch\n",
    "        self.b1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, n1x1, kernel_size=1),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "        # 1x1 -> 3x3 conv branch\n",
    "        self.b2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, n3x3red, kernel_size=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(n3x3red, n3x3, kernel_size=3, padding=1),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "        # 1x1 -> 5x5 conv branch\n",
    "        self.b3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, n5x5red, kernel_size=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(n5x5red, n5x5, kernel_size=5, padding=2),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "        # 3x3 pool -> 1x1 conv branch\n",
    "        self.b4 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            nn.Conv2d(in_channels, pool_planes, kernel_size=1),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        y1 = self.b1(x)\n",
    "        y2 = self.b2(x)\n",
    "        y3 = self.b3(x)\n",
    "        y4 = self.b4(x)\n",
    "        return torch.cat([y1, y2, y3, y4], 1)\n",
    "\n",
    "\n",
    "# PoseNet\n",
    "class PoseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PoseNet, self).__init__()\n",
    "\n",
    "        self.pre_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=2, stride=1, padding=1),\n",
    "            nn.Conv2d(8, 16, kernel_size=2, stride=1, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(16, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.LocalResponseNorm(5, 0.0001, 0.75),\n",
    "            nn.Conv2d(64, 128, kernel_size=2, stride=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(128, 192, kernel_size=2, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.LocalResponseNorm(5, 0.0001, 0.75),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.lastlayers= nn.Sequential(  nn.Dropout(p=0.5),     \n",
    "            nn.Linear(512,256),\n",
    "            nn.ReLU(True),\n",
    "                                       nn.Dropout(p=0.5),\n",
    "         nn.Linear(256, 128),\n",
    "            nn.ReLU(True), nn.Dropout(p=0.5),\n",
    "         nn.Linear(128, 64),\n",
    "            nn.ReLU(True),nn.Dropout(p=0.5),\n",
    "         nn.Linear(64, 32),\n",
    "            nn.ReLU(True),nn.Dropout(p=0.5),\n",
    "        nn.Linear(32, 16),\n",
    "            nn.ReLU(True),nn.Dropout(p=0.5),\n",
    "        nn.Linear(16, 8),\n",
    "            nn.ReLU(True),nn.Dropout(p=0.5),\n",
    "        nn.Linear(8, 2),\n",
    "            nn.Tanh()\n",
    "            \n",
    "        )\n",
    "\n",
    "        self.a3 = InceptionV1(192, 64, 96, 128, 16, 32, 32)\n",
    "        self.b3 = InceptionV1(256, 128, 128, 192, 32, 96, 64)\n",
    "\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        \n",
    "        \n",
    "        self.a4 = InceptionV1(960, 192, 96, 208, 16, 48, 64)\n",
    "        self.b4 = InceptionV1(512, 160, 112, 224, 24, 64, 64)\n",
    "        self.c4 = InceptionV1(512, 128, 128, 256, 24, 64, 64)\n",
    "        self.d4 = InceptionV1(512, 112, 144, 288, 32, 64, 64)\n",
    "        self.e4 = InceptionV1(528, 256, 160, 320, 32, 128, 128)\n",
    "\n",
    "        self.a5 = InceptionV1(832, 256, 160, 320, 32, 128, 128)\n",
    "        self.b5 = InceptionV1(832, 384, 192, 384, 48, 128, 128)\n",
    "\n",
    "        self.avg_pool = nn.AvgPool2d(kernel_size=7, stride=1)\n",
    "        self.avg_pool5x5 = nn.AvgPool2d(kernel_size=5, stride=3)\n",
    "        self.conv1x1 = nn.Conv2d(512, 128, kernel_size=1, stride=1)\n",
    "        self.conv1x12 = nn.Conv2d(528, 128, kernel_size=1, stride=1)\n",
    "        self.fc = nn.Linear(1024, 2048)\n",
    "        self.fc2048 = nn.Linear(2048, 1024)\n",
    "\n",
    "        self.dropout5 = nn.Dropout(p=0.5)\n",
    "        self.dropout7 = nn.Dropout(p=0.7)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.cls_fc_pose_xyz = nn.Linear(2048, 1024)\n",
    "#         self.cls_fc_pose_wpqr = nn.Linear(2048, 4)\n",
    "        self.cls_fc_pose_xyz_1024 = nn.Linear(1024, 512)\n",
    "#         self.cls_fc_pose_wpqr_1024 = nn.Linear(1024, 4)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x1,x2):\n",
    "        out = self.pre_layers(x1)\n",
    "        out = self.a3(out)\n",
    "        out = self.b3(out)\n",
    "        out = self.max_pool(out)\n",
    "#         out = self.a4(out)\n",
    "        \n",
    "        out2 = self.pre_layers(x1)\n",
    "        out2 = self.a3(out2)\n",
    "        out2 = self.b3(out2)\n",
    "        out2 = self.max_pool(out2)\n",
    "            \n",
    "        \n",
    "        out = torch.cat((out, out2), dim=1)\n",
    "        out = self.a4(out)   \n",
    "#         out = self.max_pool(out)\n",
    "\n",
    "        cls1_pool = self.avg_pool5x5(out)\n",
    "        cls1_reduction = self.conv1x1(cls1_pool)\n",
    "        cls1_reduction = F.relu(cls1_reduction)\n",
    "        cls1_reduction = cls1_reduction.view(cls1_reduction.size(0), -1)\n",
    "        cls1_fc1 = self.fc2048(cls1_reduction)\n",
    "        cls1_fc1 = self.relu(cls1_fc1)\n",
    "        cls1_fc1 = self.dropout7(cls1_fc1)\n",
    "        cls1_fc_pose_xyz = self.cls_fc_pose_xyz_1024(cls1_fc1)\n",
    "        cls1_fc_pose_xyz = self.lastlayers(cls1_fc_pose_xyz)\n",
    "#         cls1_pose_wpqr = self.cls_fc_pose_wpqr_1024(cls1_fc1)\n",
    "\n",
    "        out = self.b4(out)\n",
    "        out = self.c4(out)\n",
    "        out = self.d4(out)\n",
    "        cls2_pool = self.avg_pool5x5(out)\n",
    "        cls2_reduction = self.conv1x12(cls2_pool)\n",
    "        cls2_reduction = F.relu(cls2_reduction)\n",
    "        cls2_reduction = cls2_reduction.view(cls2_reduction.size(0), -1)\n",
    "        cls2_fc1 = self.fc2048(cls2_reduction)\n",
    "        cls2_fc1 = self.relu(cls2_fc1)\n",
    "        cls2_fc1 = self.dropout7(cls2_fc1)\n",
    "        cls2_fc_pose_xyz = self.cls_fc_pose_xyz_1024(cls2_fc1)\n",
    "        cls2_fc_pose_xyz = self.lastlayers(cls2_fc_pose_xyz)\n",
    "\n",
    "#         cls2_pose_wpqr = self.cls_fc_pose_wpqr_1024(cls2_fc1)\n",
    "        out = self.e4(out)\n",
    "\n",
    "        out = self.max_pool(out)\n",
    "\n",
    "        out = self.a5(out)\n",
    "        out = self.b5(out)\n",
    "        cls3_pool = self.avg_pool(out)\n",
    "        cls3_pool = cls3_pool.view(cls3_pool.size(0), -1)\n",
    "        cls3_fc1 = self.fc(cls3_pool)\n",
    "        cls3_fc1 = self.relu(cls3_fc1)\n",
    "        cls3_fc1 = self.dropout5(cls3_fc1)\n",
    "        cls3_fc_pose_xyz = self.cls_fc_pose_xyz(cls3_fc1)\n",
    "        cls3_fc_pose_xyz = self.cls_fc_pose_xyz_1024(cls3_fc_pose_xyz)\n",
    "        cls3_fc_pose_xyz = self.lastlayers(cls3_fc_pose_xyz)\n",
    "\n",
    "#         cls3_pose_wpqr = self.cls_fc_pose_wpqr(cls3_fc1)\n",
    "\n",
    "        return cls1_fc_pose_xyz, \\\n",
    "               cls2_fc_pose_xyz, \\\n",
    "               cls3_fc_pose_xyz\n",
    "# , \\              cls3_pose_wpqr\n",
    "\n",
    "\n",
    "class PoseLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, w1_x, w2_x, w3_x):\n",
    "        super(PoseLoss, self).__init__()\n",
    "        self.w1_x = w1_x\n",
    "        self.w2_x = w2_x\n",
    "        self.w3_x = w3_x\n",
    "#         self.w1_q = w1_q\n",
    "#         self.w2_q = w2_q\n",
    "#         self.w3_q = w3_q\n",
    "        return\n",
    "\n",
    "    def forward(self, p1_x, p2_x, p3_x, poseGT):\n",
    "        pose_x = poseGT\n",
    "#         pose_q = poseGT[:, 3:]\n",
    "\n",
    "        l1_x = torch.sqrt(torch.sum(Variable(torch.Tensor(np.square(F.pairwise_distance(pose_x, p1_x).detach().cpu().numpy())), requires_grad=True))) * self.w1_x\n",
    "#         l1_q = torch.sqrt(torch.sum(Variable(torch.Tensor(np.square(F.pairwise_distance(pose_q, p1_q).detach().cpu().numpy())), requires_grad=True))) * self.w1_q\n",
    "        l2_x = torch.sqrt(torch.sum(Variable(torch.Tensor(np.square(F.pairwise_distance(pose_x, p2_x).detach().cpu().numpy())), requires_grad=True))) * self.w2_x\n",
    "#         l2_q = torch.sqrt(torch.sum(Variable(torch.Tensor(np.square(F.pairwise_distance(pose_q, p2_q).detach().cpu().numpy())), requires_grad=True))) * self.w2_q\n",
    "        l3_x = torch.sqrt(torch.sum(Variable(torch.Tensor(np.square(F.pairwise_distance(pose_x, p3_x).detach().cpu().numpy())), requires_grad=True))) * self.w3_x\n",
    "#         l3_q = torch.sqrt(torch.sum(Variable(torch.Tensor(np.square(F.pairwise_distance(pose_q, p3_q).detach().cpu().numpy())), requires_grad=True))) * self.w3_q\n",
    "\n",
    "        loss = l1_x  + l2_x + l3_x \n",
    "        return loss\n",
    "\n",
    "\n",
    "# def posenet_v1():\n",
    "#     model = PoseNet()\n",
    "#     return model\n",
    "\n",
    "model = PoseNet()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 8, 225, 225]              40\n",
      "            Conv2d-2         [-1, 16, 226, 226]             528\n",
      "              ReLU-3         [-1, 16, 226, 226]               0\n",
      "            Conv2d-4         [-1, 64, 113, 113]          50,240\n",
      "         MaxPool2d-5           [-1, 64, 56, 56]               0\n",
      " LocalResponseNorm-6           [-1, 64, 56, 56]               0\n",
      "            Conv2d-7          [-1, 128, 55, 55]          32,896\n",
      "              ReLU-8          [-1, 128, 55, 55]               0\n",
      "            Conv2d-9          [-1, 192, 56, 56]          98,496\n",
      "             ReLU-10          [-1, 192, 56, 56]               0\n",
      "LocalResponseNorm-11          [-1, 192, 56, 56]               0\n",
      "        MaxPool2d-12          [-1, 192, 27, 27]               0\n",
      "           Conv2d-13           [-1, 64, 27, 27]          12,352\n",
      "             ReLU-14           [-1, 64, 27, 27]               0\n",
      "           Conv2d-15           [-1, 96, 27, 27]          18,528\n",
      "             ReLU-16           [-1, 96, 27, 27]               0\n",
      "           Conv2d-17          [-1, 128, 27, 27]         110,720\n",
      "             ReLU-18          [-1, 128, 27, 27]               0\n",
      "           Conv2d-19           [-1, 16, 27, 27]           3,088\n",
      "             ReLU-20           [-1, 16, 27, 27]               0\n",
      "           Conv2d-21           [-1, 32, 27, 27]          12,832\n",
      "             ReLU-22           [-1, 32, 27, 27]               0\n",
      "        MaxPool2d-23          [-1, 192, 27, 27]               0\n",
      "           Conv2d-24           [-1, 32, 27, 27]           6,176\n",
      "             ReLU-25           [-1, 32, 27, 27]               0\n",
      "      InceptionV1-26          [-1, 256, 27, 27]               0\n",
      "           Conv2d-27          [-1, 128, 27, 27]          32,896\n",
      "             ReLU-28          [-1, 128, 27, 27]               0\n",
      "           Conv2d-29          [-1, 128, 27, 27]          32,896\n",
      "             ReLU-30          [-1, 128, 27, 27]               0\n",
      "           Conv2d-31          [-1, 192, 27, 27]         221,376\n",
      "             ReLU-32          [-1, 192, 27, 27]               0\n",
      "           Conv2d-33           [-1, 32, 27, 27]           8,224\n",
      "             ReLU-34           [-1, 32, 27, 27]               0\n",
      "           Conv2d-35           [-1, 96, 27, 27]          76,896\n",
      "             ReLU-36           [-1, 96, 27, 27]               0\n",
      "        MaxPool2d-37          [-1, 256, 27, 27]               0\n",
      "           Conv2d-38           [-1, 64, 27, 27]          16,448\n",
      "             ReLU-39           [-1, 64, 27, 27]               0\n",
      "      InceptionV1-40          [-1, 480, 27, 27]               0\n",
      "        MaxPool2d-41          [-1, 480, 14, 14]               0\n",
      "           Conv2d-42          [-1, 8, 225, 225]              40\n",
      "           Conv2d-43         [-1, 16, 226, 226]             528\n",
      "             ReLU-44         [-1, 16, 226, 226]               0\n",
      "           Conv2d-45         [-1, 64, 113, 113]          50,240\n",
      "        MaxPool2d-46           [-1, 64, 56, 56]               0\n",
      "LocalResponseNorm-47           [-1, 64, 56, 56]               0\n",
      "           Conv2d-48          [-1, 128, 55, 55]          32,896\n",
      "             ReLU-49          [-1, 128, 55, 55]               0\n",
      "           Conv2d-50          [-1, 192, 56, 56]          98,496\n",
      "             ReLU-51          [-1, 192, 56, 56]               0\n",
      "LocalResponseNorm-52          [-1, 192, 56, 56]               0\n",
      "        MaxPool2d-53          [-1, 192, 27, 27]               0\n",
      "           Conv2d-54           [-1, 64, 27, 27]          12,352\n",
      "             ReLU-55           [-1, 64, 27, 27]               0\n",
      "           Conv2d-56           [-1, 96, 27, 27]          18,528\n",
      "             ReLU-57           [-1, 96, 27, 27]               0\n",
      "           Conv2d-58          [-1, 128, 27, 27]         110,720\n",
      "             ReLU-59          [-1, 128, 27, 27]               0\n",
      "           Conv2d-60           [-1, 16, 27, 27]           3,088\n",
      "             ReLU-61           [-1, 16, 27, 27]               0\n",
      "           Conv2d-62           [-1, 32, 27, 27]          12,832\n",
      "             ReLU-63           [-1, 32, 27, 27]               0\n",
      "        MaxPool2d-64          [-1, 192, 27, 27]               0\n",
      "           Conv2d-65           [-1, 32, 27, 27]           6,176\n",
      "             ReLU-66           [-1, 32, 27, 27]               0\n",
      "      InceptionV1-67          [-1, 256, 27, 27]               0\n",
      "           Conv2d-68          [-1, 128, 27, 27]          32,896\n",
      "             ReLU-69          [-1, 128, 27, 27]               0\n",
      "           Conv2d-70          [-1, 128, 27, 27]          32,896\n",
      "             ReLU-71          [-1, 128, 27, 27]               0\n",
      "           Conv2d-72          [-1, 192, 27, 27]         221,376\n",
      "             ReLU-73          [-1, 192, 27, 27]               0\n",
      "           Conv2d-74           [-1, 32, 27, 27]           8,224\n",
      "             ReLU-75           [-1, 32, 27, 27]               0\n",
      "           Conv2d-76           [-1, 96, 27, 27]          76,896\n",
      "             ReLU-77           [-1, 96, 27, 27]               0\n",
      "        MaxPool2d-78          [-1, 256, 27, 27]               0\n",
      "           Conv2d-79           [-1, 64, 27, 27]          16,448\n",
      "             ReLU-80           [-1, 64, 27, 27]               0\n",
      "      InceptionV1-81          [-1, 480, 27, 27]               0\n",
      "        MaxPool2d-82          [-1, 480, 14, 14]               0\n",
      "           Conv2d-83          [-1, 192, 14, 14]         184,512\n",
      "             ReLU-84          [-1, 192, 14, 14]               0\n",
      "           Conv2d-85           [-1, 96, 14, 14]          92,256\n",
      "             ReLU-86           [-1, 96, 14, 14]               0\n",
      "           Conv2d-87          [-1, 208, 14, 14]         179,920\n",
      "             ReLU-88          [-1, 208, 14, 14]               0\n",
      "           Conv2d-89           [-1, 16, 14, 14]          15,376\n",
      "             ReLU-90           [-1, 16, 14, 14]               0\n",
      "           Conv2d-91           [-1, 48, 14, 14]          19,248\n",
      "             ReLU-92           [-1, 48, 14, 14]               0\n",
      "        MaxPool2d-93          [-1, 960, 14, 14]               0\n",
      "           Conv2d-94           [-1, 64, 14, 14]          61,504\n",
      "             ReLU-95           [-1, 64, 14, 14]               0\n",
      "      InceptionV1-96          [-1, 512, 14, 14]               0\n",
      "        AvgPool2d-97            [-1, 512, 4, 4]               0\n",
      "           Conv2d-98            [-1, 128, 4, 4]          65,664\n",
      "           Linear-99                 [-1, 1024]       2,098,176\n",
      "            ReLU-100                 [-1, 1024]               0\n",
      "         Dropout-101                 [-1, 1024]               0\n",
      "          Linear-102                  [-1, 512]         524,800\n",
      "         Dropout-103                  [-1, 512]               0\n",
      "          Linear-104                  [-1, 256]         131,328\n",
      "            ReLU-105                  [-1, 256]               0\n",
      "         Dropout-106                  [-1, 256]               0\n",
      "          Linear-107                  [-1, 128]          32,896\n",
      "            ReLU-108                  [-1, 128]               0\n",
      "         Dropout-109                  [-1, 128]               0\n",
      "          Linear-110                   [-1, 64]           8,256\n",
      "            ReLU-111                   [-1, 64]               0\n",
      "         Dropout-112                   [-1, 64]               0\n",
      "          Linear-113                   [-1, 32]           2,080\n",
      "            ReLU-114                   [-1, 32]               0\n",
      "         Dropout-115                   [-1, 32]               0\n",
      "          Linear-116                   [-1, 16]             528\n",
      "            ReLU-117                   [-1, 16]               0\n",
      "         Dropout-118                   [-1, 16]               0\n",
      "          Linear-119                    [-1, 8]             136\n",
      "            ReLU-120                    [-1, 8]               0\n",
      "         Dropout-121                    [-1, 8]               0\n",
      "          Linear-122                    [-1, 2]              18\n",
      "            Tanh-123                    [-1, 2]               0\n",
      "          Conv2d-124          [-1, 160, 14, 14]          82,080\n",
      "            ReLU-125          [-1, 160, 14, 14]               0\n",
      "          Conv2d-126          [-1, 112, 14, 14]          57,456\n",
      "            ReLU-127          [-1, 112, 14, 14]               0\n",
      "          Conv2d-128          [-1, 224, 14, 14]         226,016\n",
      "            ReLU-129          [-1, 224, 14, 14]               0\n",
      "          Conv2d-130           [-1, 24, 14, 14]          12,312\n",
      "            ReLU-131           [-1, 24, 14, 14]               0\n",
      "          Conv2d-132           [-1, 64, 14, 14]          38,464\n",
      "            ReLU-133           [-1, 64, 14, 14]               0\n",
      "       MaxPool2d-134          [-1, 512, 14, 14]               0\n",
      "          Conv2d-135           [-1, 64, 14, 14]          32,832\n",
      "            ReLU-136           [-1, 64, 14, 14]               0\n",
      "     InceptionV1-137          [-1, 512, 14, 14]               0\n",
      "          Conv2d-138          [-1, 128, 14, 14]          65,664\n",
      "            ReLU-139          [-1, 128, 14, 14]               0\n",
      "          Conv2d-140          [-1, 128, 14, 14]          65,664\n",
      "            ReLU-141          [-1, 128, 14, 14]               0\n",
      "          Conv2d-142          [-1, 256, 14, 14]         295,168\n",
      "            ReLU-143          [-1, 256, 14, 14]               0\n",
      "          Conv2d-144           [-1, 24, 14, 14]          12,312\n",
      "            ReLU-145           [-1, 24, 14, 14]               0\n",
      "          Conv2d-146           [-1, 64, 14, 14]          38,464\n",
      "            ReLU-147           [-1, 64, 14, 14]               0\n",
      "       MaxPool2d-148          [-1, 512, 14, 14]               0\n",
      "          Conv2d-149           [-1, 64, 14, 14]          32,832\n",
      "            ReLU-150           [-1, 64, 14, 14]               0\n",
      "     InceptionV1-151          [-1, 512, 14, 14]               0\n",
      "          Conv2d-152          [-1, 112, 14, 14]          57,456\n",
      "            ReLU-153          [-1, 112, 14, 14]               0\n",
      "          Conv2d-154          [-1, 144, 14, 14]          73,872\n",
      "            ReLU-155          [-1, 144, 14, 14]               0\n",
      "          Conv2d-156          [-1, 288, 14, 14]         373,536\n",
      "            ReLU-157          [-1, 288, 14, 14]               0\n",
      "          Conv2d-158           [-1, 32, 14, 14]          16,416\n",
      "            ReLU-159           [-1, 32, 14, 14]               0\n",
      "          Conv2d-160           [-1, 64, 14, 14]          51,264\n",
      "            ReLU-161           [-1, 64, 14, 14]               0\n",
      "       MaxPool2d-162          [-1, 512, 14, 14]               0\n",
      "          Conv2d-163           [-1, 64, 14, 14]          32,832\n",
      "            ReLU-164           [-1, 64, 14, 14]               0\n",
      "     InceptionV1-165          [-1, 528, 14, 14]               0\n",
      "       AvgPool2d-166            [-1, 528, 4, 4]               0\n",
      "          Conv2d-167            [-1, 128, 4, 4]          67,712\n",
      "          Linear-168                 [-1, 1024]       2,098,176\n",
      "            ReLU-169                 [-1, 1024]               0\n",
      "         Dropout-170                 [-1, 1024]               0\n",
      "          Linear-171                  [-1, 512]         524,800\n",
      "         Dropout-172                  [-1, 512]               0\n",
      "          Linear-173                  [-1, 256]         131,328\n",
      "            ReLU-174                  [-1, 256]               0\n",
      "         Dropout-175                  [-1, 256]               0\n",
      "          Linear-176                  [-1, 128]          32,896\n",
      "            ReLU-177                  [-1, 128]               0\n",
      "         Dropout-178                  [-1, 128]               0\n",
      "          Linear-179                   [-1, 64]           8,256\n",
      "            ReLU-180                   [-1, 64]               0\n",
      "         Dropout-181                   [-1, 64]               0\n",
      "          Linear-182                   [-1, 32]           2,080\n",
      "            ReLU-183                   [-1, 32]               0\n",
      "         Dropout-184                   [-1, 32]               0\n",
      "          Linear-185                   [-1, 16]             528\n",
      "            ReLU-186                   [-1, 16]               0\n",
      "         Dropout-187                   [-1, 16]               0\n",
      "          Linear-188                    [-1, 8]             136\n",
      "            ReLU-189                    [-1, 8]               0\n",
      "         Dropout-190                    [-1, 8]               0\n",
      "          Linear-191                    [-1, 2]              18\n",
      "            Tanh-192                    [-1, 2]               0\n",
      "          Conv2d-193          [-1, 256, 14, 14]         135,424\n",
      "            ReLU-194          [-1, 256, 14, 14]               0\n",
      "          Conv2d-195          [-1, 160, 14, 14]          84,640\n",
      "            ReLU-196          [-1, 160, 14, 14]               0\n",
      "          Conv2d-197          [-1, 320, 14, 14]         461,120\n",
      "            ReLU-198          [-1, 320, 14, 14]               0\n",
      "          Conv2d-199           [-1, 32, 14, 14]          16,928\n",
      "            ReLU-200           [-1, 32, 14, 14]               0\n",
      "          Conv2d-201          [-1, 128, 14, 14]         102,528\n",
      "            ReLU-202          [-1, 128, 14, 14]               0\n",
      "       MaxPool2d-203          [-1, 528, 14, 14]               0\n",
      "          Conv2d-204          [-1, 128, 14, 14]          67,712\n",
      "            ReLU-205          [-1, 128, 14, 14]               0\n",
      "     InceptionV1-206          [-1, 832, 14, 14]               0\n",
      "       MaxPool2d-207            [-1, 832, 7, 7]               0\n",
      "          Conv2d-208            [-1, 256, 7, 7]         213,248\n",
      "            ReLU-209            [-1, 256, 7, 7]               0\n",
      "          Conv2d-210            [-1, 160, 7, 7]         133,280\n",
      "            ReLU-211            [-1, 160, 7, 7]               0\n",
      "          Conv2d-212            [-1, 320, 7, 7]         461,120\n",
      "            ReLU-213            [-1, 320, 7, 7]               0\n",
      "          Conv2d-214             [-1, 32, 7, 7]          26,656\n",
      "            ReLU-215             [-1, 32, 7, 7]               0\n",
      "          Conv2d-216            [-1, 128, 7, 7]         102,528\n",
      "            ReLU-217            [-1, 128, 7, 7]               0\n",
      "       MaxPool2d-218            [-1, 832, 7, 7]               0\n",
      "          Conv2d-219            [-1, 128, 7, 7]         106,624\n",
      "            ReLU-220            [-1, 128, 7, 7]               0\n",
      "     InceptionV1-221            [-1, 832, 7, 7]               0\n",
      "          Conv2d-222            [-1, 384, 7, 7]         319,872\n",
      "            ReLU-223            [-1, 384, 7, 7]               0\n",
      "          Conv2d-224            [-1, 192, 7, 7]         159,936\n",
      "            ReLU-225            [-1, 192, 7, 7]               0\n",
      "          Conv2d-226            [-1, 384, 7, 7]         663,936\n",
      "            ReLU-227            [-1, 384, 7, 7]               0\n",
      "          Conv2d-228             [-1, 48, 7, 7]          39,984\n",
      "            ReLU-229             [-1, 48, 7, 7]               0\n",
      "          Conv2d-230            [-1, 128, 7, 7]         153,728\n",
      "            ReLU-231            [-1, 128, 7, 7]               0\n",
      "       MaxPool2d-232            [-1, 832, 7, 7]               0\n",
      "          Conv2d-233            [-1, 128, 7, 7]         106,624\n",
      "            ReLU-234            [-1, 128, 7, 7]               0\n",
      "     InceptionV1-235           [-1, 1024, 7, 7]               0\n",
      "       AvgPool2d-236           [-1, 1024, 1, 1]               0\n",
      "          Linear-237                 [-1, 2048]       2,099,200\n",
      "            ReLU-238                 [-1, 2048]               0\n",
      "         Dropout-239                 [-1, 2048]               0\n",
      "          Linear-240                 [-1, 1024]       2,098,176\n",
      "          Linear-241                  [-1, 512]         524,800\n",
      "         Dropout-242                  [-1, 512]               0\n",
      "          Linear-243                  [-1, 256]         131,328\n",
      "            ReLU-244                  [-1, 256]               0\n",
      "         Dropout-245                  [-1, 256]               0\n",
      "          Linear-246                  [-1, 128]          32,896\n",
      "            ReLU-247                  [-1, 128]               0\n",
      "         Dropout-248                  [-1, 128]               0\n",
      "          Linear-249                   [-1, 64]           8,256\n",
      "            ReLU-250                   [-1, 64]               0\n",
      "         Dropout-251                   [-1, 64]               0\n",
      "          Linear-252                   [-1, 32]           2,080\n",
      "            ReLU-253                   [-1, 32]               0\n",
      "         Dropout-254                   [-1, 32]               0\n",
      "          Linear-255                   [-1, 16]             528\n",
      "            ReLU-256                   [-1, 16]               0\n",
      "         Dropout-257                   [-1, 16]               0\n",
      "          Linear-258                    [-1, 8]             136\n",
      "            ReLU-259                    [-1, 8]               0\n",
      "         Dropout-260                    [-1, 8]               0\n",
      "          Linear-261                    [-1, 2]              18\n",
      "            Tanh-262                    [-1, 2]               0\n",
      "================================================================\n",
      "Total params: 17,569,838\n",
      "Trainable params: 17,569,838\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 9604.00\n",
      "Forward/backward pass size (MB): 151.73\n",
      "Params size (MB): 67.02\n",
      "Estimated Total Size (MB): 9822.76\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, [(1, 224, 224),(1, 224, 224)])\n",
    "# summary(model, (1, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(epoch, train_loss, val_loss, train_mae, val_mae, train_accuracy, val_accuracy, output_dir):\n",
    "    with open(os.path.join(output_dir, 'training_results.txt'), 'a') as f:\n",
    "        f.write(f'Epoch [{epoch+1}], Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, '\n",
    "                f'Train MAE: {train_mae:.4f}, Validation MAE: {val_mae:.4f}, '\n",
    "                f'Train Accuracy: {train_accuracy:.4f}, Validation Accuracy: {val_accuracy:.4f}\\n')\n",
    "\n",
    "\n",
    "# Get the current date and time\n",
    "current_time = datetime.now().strftime(\"%Y_%m_%d-%H:%M:%S\")\n",
    "\n",
    "# Create a directory to save results using the current timestamp\n",
    "output_dir = f'posenet_results_{current_time}'\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.MSELoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "learning_rate = 0.001\n",
    "batch_size = 16\n",
    "EPOCHS = 80000\n",
    "\n",
    "criterion = PoseLoss(0.3, 0.3, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eY3rPw7wPVEe",
    "outputId": "213b5a1c-d9f4-4659-f6dc-b6ff9d0d1a44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading image /workspace/processed/D6_1/target.jpg: name 'kernel' is not defined\n",
      "Error loading image /workspace/processed/D6_1/img04660.jpg: name 'kernel' is not defined\n",
      "Failed to load images: /workspace/processed/D6_1/target.jpg, /workspace/processed/D6_1/img04660.jpg\n",
      "Error loading image /workspace/processed/D8_1_2_3/target.jpg: name 'kernel' is not defined\n",
      "Error loading image /workspace/processed/D8_1_2_3/img0010.jpg: name 'kernel' is not defined\n",
      "Failed to load images: /workspace/processed/D8_1_2_3/target.jpg, /workspace/processed/D8_1_2_3/img0010.jpg\n",
      "Error loading image /workspace/processed/D9_1_2_3/target.jpg: name 'kernel' is not defined\n",
      "Error loading image /workspace/processed/D9_1_2_3/img01649.jpg: name 'kernel' is not defined\n",
      "Failed to load images: /workspace/processed/D9_1_2_3/target.jpg, /workspace/processed/D9_1_2_3/img01649.jpg\n",
      "Error loading image /workspace/processed/D6/target.jpg: name 'kernel' is not defined\n",
      "Error loading image /workspace/processed/D6/img040.jpg: name 'kernel' is not defined\n",
      "Failed to load images: /workspace/processed/D6/target.jpg, /workspace/processed/D6/img040.jpg\n",
      "Error loading image /workspace/processed/D4_1_2_3/target.jpg: name 'kernel' is not defined\n",
      "Error loading image /workspace/processed/D4_1_2_3/img01618.jpg: name 'kernel' is not defined\n",
      "Failed to load images: /workspace/processed/D4_1_2_3/target.jpg, /workspace/processed/D4_1_2_3/img01618.jpg\n",
      "Error loading image /workspace/processed/D8_1/target.jpg: name 'kernel' is not defined\n",
      "Error loading image /workspace/processed/D8_1/img001.jpg: name 'kernel' is not defined\n",
      "Failed to load images: /workspace/processed/D8_1/target.jpg, /workspace/processed/D8_1/img001.jpg\n",
      "Error loading image /workspace/processed/D4_1_2/target.jpg: name 'kernel' is not defined\n",
      "Error loading image /workspace/processed/D4_1_2/img01618.jpg: name 'kernel' is not defined\n",
      "Failed to load images: /workspace/processed/D4_1_2/target.jpg, /workspace/processed/D4_1_2/img01618.jpg\n",
      "Error loading image /workspace/processed/D3_1_2_3/target.jpg: name 'kernel' is not defined\n",
      "Error loading image /workspace/processed/D3_1_2_3/img016.jpg: name 'kernel' is not defined\n",
      "Failed to load images: /workspace/processed/D3_1_2_3/target.jpg, /workspace/processed/D3_1_2_3/img016.jpg\n",
      "Error loading image /workspace/processed/D7_1/target.jpg: name 'kernel' is not defined\n",
      "Error loading image /workspace/processed/D7_1/img00619.jpg: name 'kernel' is not defined\n",
      "Failed to load images: /workspace/processed/D7_1/target.jpg, /workspace/processed/D7_1/img00619.jpg\n",
      "Error loading image /workspace/processed/D8/target.jpg: name 'kernel' is not defined\n",
      "Error loading image /workspace/processed/D8/img01548.jpg: name 'kernel' is not defined\n",
      "Failed to load images: /workspace/processed/D8/target.jpg, /workspace/processed/D8/img01548.jpg\n",
      "Error loading image /workspace/processed/D3_1_2_3/target.jpg: name 'kernel' is not defined\n",
      "Error loading image /workspace/processed/D3_1_2_3/img005.jpg: name 'kernel' is not defined\n",
      "Failed to load images: /workspace/processed/D3_1_2_3/target.jpg, /workspace/processed/D3_1_2_3/img005.jpg\n",
      "Error loading image /workspace/processed/D8/target.jpg: name 'kernel' is not defined\n",
      "Error loading image /workspace/processed/D8/img0047.jpg: name 'kernel' is not defined\n",
      "Failed to load images: /workspace/processed/D8/target.jpg, /workspace/processed/D8/img0047.jpg\n",
      "Error loading image /workspace/processed/D3_1/target.jpg: name 'kernel' is not defined\n",
      "Error loading image /workspace/processed/D3_1/img013.jpg: name 'kernel' is not defined\n",
      "Failed to load images: /workspace/processed/D3_1/target.jpg, /workspace/processed/D3_1/img013.jpg\n",
      "Error loading image /workspace/processed/D8_1_2_3/target.jpg: name 'kernel' is not defined\n",
      "Error loading image /workspace/processed/D8_1_2_3/img01030.jpg: name 'kernel' is not defined\n",
      "Failed to load images: /workspace/processed/D8_1_2_3/target.jpg, /workspace/processed/D8_1_2_3/img01030.jpg\n",
      "Error loading image /workspace/processed/D5_1_2_3/target.jpg: name 'kernel' is not defined\n",
      "Error loading image /workspace/processed/D5_1_2_3/img02840.jpg: name 'kernel' is not defined\n",
      "Failed to load images: /workspace/processed/D5_1_2_3/target.jpg, /workspace/processed/D5_1_2_3/img02840.jpg\n",
      "Error loading image /workspace/processed/D5_1/target.jpg: name 'kernel' is not defined\n",
      "Error loading image /workspace/processed/D5_1/img015.jpg: name 'kernel' is not defined\n",
      "Failed to load images: /workspace/processed/D5_1/target.jpg, /workspace/processed/D5_1/img015.jpg\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1418/430313943.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#    running_mae = 0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#    running_corrects = 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mtarget_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mtarget_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(nn.ParameterList(model.parameters()), lr=learning_rate)\n",
    "\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "# train_maes = []\n",
    "# val_maes = []\n",
    "# train_accuracies = []\n",
    "# val_accuracies = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "#    running_mae = 0.0\n",
    "#    running_corrects = 0\n",
    "    for i, (inputs, poses) in enumerate(train_loader):\n",
    "            (target_images, X2_images), poses = inputs, poses\n",
    "            target_images, X2_images, poses = target_images.to(device), X2_images.to(device), poses.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            p1_x, p2_x, p3_x = model(target_images, X2_images)\n",
    "            loss = criterion(p1_x, p2_x, p3_x, poses)\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            running_loss += loss.item()\n",
    "#         running_mae += mae.item()\n",
    "#         running_corrects += accuracy(outputs, labels)\n",
    "\n",
    "#             if i % 20 == 0:\n",
    "#                 print(\"iteration: \" + str(epoch) + \"\\n    \" + \"Loss is: \" + str(loss)\n",
    "    train_losses.append(running_loss / len(train_loader))\n",
    "#     train_maes.append(running_mae / len(train_loader))\n",
    "#     train_accuracies.append(running_corrects / len(train_loader))\n",
    "        \n",
    "    # Validation step\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "#     val_mae = 0.0\n",
    "#     val_corrects = 0\n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:\n",
    "            (target_images, X2_images), poses = data\n",
    "            target_images, X2_images, poses = target_images.to(device), X2_images.to(device), poses.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            p1_x, p2_x, p3_x = model(target_images, X2_images)\n",
    "            vloss = criterion(p1_x, p2_x, p3_x, poses)\n",
    "\n",
    "#             vloss = vloss1+vloss2+vloss3\n",
    "#             mae = mae_criterion(outputs, labels)\n",
    "            val_loss += vloss.item()\n",
    "#             val_mae += mae.item()\n",
    "#             val_corrects += accuracy(outputs, labels)\n",
    "    \n",
    "    val_losses.append(val_loss / len(val_loader))\n",
    "#     val_maes.append(val_mae / len(val_loader))\n",
    "#     val_accuracies.append(val_corrects / len(val_loader))\n",
    "    \n",
    "#     save_results(epoch, train_losses[-1], val_losses[-1], train_maes[-1], val_maes[-1], train_accuracies[-1], val_accuracies[-1], output_dir)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{EPOCHS}], Train Loss: {train_losses[-1]:.4f}, Validation Loss: {val_losses[-1]:.4f}')\n",
    "\n",
    "print('Training Done')\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'results_{current_time}posenet.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.SGD(nn.ParameterList(model.parameters()), lr=learning_rate)\n",
    "# for epoch in range(EPOCHS):\n",
    "#     model.train()\n",
    "#     for i, (inputs, poses) in enumerate(train_loader):\n",
    "#             (target_images, X2_images), poses = inputs, poses\n",
    "#             target_images, X2_images, poses = target_images.to(device), X2_images.to(device), poses.to(device)\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "\n",
    "\n",
    "#             p1_x, p2_x, p3_x = model(target_images, X2_images)\n",
    "#             loss1 = criterion(p1_x, poses)\n",
    "#             loss2= criterion(p1_x, poses)\n",
    "#             loss3 = criterion(p1_x, poses)\n",
    "#             loss = loss1+loss2+loss3\n",
    "# #             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             if i % 20 == 0:\n",
    "#                 print(\"iteration: \" + str(epoch) + \"\\n    \" + \"Loss is: \" + str(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oeVRGN56hkNZ"
   },
   "outputs": [],
   "source": [
    "\n",
    "# total_loss = 0\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for data in val_loader:\n",
    "#         (target_images, X2_images), labels = data\n",
    "#         target_images, X2_images, labels = target_images.to(device), X2_images.to(device), labels.to(device)\n",
    "# #         print(target_images.size())\n",
    "        \n",
    "#         outputs = model(target_images, X2_images)\n",
    "# #         print(outputs.size())\n",
    "# #         print(\"____\\n\")\n",
    "        \n",
    "#         loss = criterion(outputs, labels)\n",
    "#         total_loss += loss.item()\n",
    "# #         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# avg_loss = total_loss / len(val_loader)\n",
    "# print('Validation Loss: ', avg_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import torch\n",
    "# from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# # Define a function to convert continuous values to discrete classes\n",
    "# def continuous_to_discrete(y):\n",
    "#     y_discrete = np.zeros_like(y)\n",
    "#     y_discrete[y > 0.5] = 1\n",
    "#     y_discrete[y < -0.5] = -1\n",
    "#     return y_discrete\n",
    "\n",
    "# # Define a function to extract true and predicted values\n",
    "# def extract_true_and_predicted_values(loader, model, device):\n",
    "#     model.eval()\n",
    "#     true_y1 = []\n",
    "#     true_y2 = []\n",
    "#     pred_y1 = []\n",
    "#     pred_y2 = []\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for data in loader:\n",
    "#             (target_images, X2_images), labels = data\n",
    "#             target_images, X2_images, labels = target_images.to(device), X2_images.to(device), labels.to(device)\n",
    "#             outputs = model(target_images, X2_images)\n",
    "\n",
    "#             true_y1.extend(labels[:, 0].cpu().numpy())\n",
    "#             true_y2.extend(labels[:, 1].cpu().numpy())\n",
    "#             pred_y1.extend(outputs[:, 0].cpu().numpy())\n",
    "#             pred_y2.extend(outputs[:, 1].cpu().numpy())\n",
    "\n",
    "#     return np.array(true_y1), np.array(pred_y1), np.array(true_y2), np.array(pred_y2)\n",
    "\n",
    "# # Extract true and predicted values\n",
    "# true_y1, pred_y1, true_y2, pred_y2 = extract_true_and_predicted_values(val_loader, model, device)\n",
    "\n",
    "# # Convert continuous predictions and true values to discrete classes\n",
    "# true_y1_discrete = continuous_to_discrete(true_y1)\n",
    "# pred_y1_discrete = continuous_to_discrete(pred_y1)\n",
    "# true_y2_discrete = continuous_to_discrete(true_y2)\n",
    "# pred_y2_discrete = continuous_to_discrete(pred_y2)\n",
    "\n",
    "# # print(true_y1_discrete-pred_y1_discrete)\n",
    "# # print()\n",
    "# # Generate confusion matrices\n",
    "# cm_y1 = confusion_matrix(true_y1_discrete, pred_y1_discrete , labels=[-1, 0, 1])\n",
    "# cm_y2 = confusion_matrix(true_y2_discrete, pred_y2_discrete , labels=[-1, 0, 1])\n",
    "\n",
    "# # Plot confusion matrices\n",
    "# fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# # ConfusionMatrixDisplay(cm_y1).plot(ax=ax[0])\n",
    "# sns.heatmap(cm_y1, annot=True, fmt='d', cmap='Blues', ax=ax[0], cbar=False)\n",
    "\n",
    "# ax[0].set_title('Confusion Matrix for y1')\n",
    "# ax[0].set_xticklabels(['-1', '0', '1'])\n",
    "# ax[0].set_yticklabels(['-1', '0', '1'])\n",
    "\n",
    "# # ConfusionMatrixDisplay(cm_y2).plot(ax=ax[1])\n",
    "# sns.heatmap(cm_y2, annot=True, fmt='d', cmap='Blues', ax=ax[1], cbar=False)\n",
    "\n",
    "# ax[1].set_title('Confusion Matrix for y2')\n",
    "# ax[1].set_xticklabels(['-1', '0', '1'])\n",
    "# ax[1].set_yticklabels(['-1', '0', '1'])\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_image_path = './processed/D9/img026.jpg'\n",
    "# target_image_path= './processed/D9/target.jpg'\n",
    "\n",
    "# # Load the images\n",
    "# target_image = load_image(target_image_path).unsqueeze(0).to(device)  # Adding batch dimension\n",
    "# test_image = load_image(test_image_path).unsqueeze(0).to(device)     # Adding batch dimension\n",
    "\n",
    "# print(\"target state image is of shape\",target_image.shape)  # Expected: torch.Size([1, 1, 200, 200])\n",
    "# print(\"current state frame is of shape\",test_image.shape)    # Expected: torch.Size([1, 1, 200, 200])\n",
    "\n",
    "# # Evaluate the model\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     outputs = model(target_image, test_image)\n",
    "#     print(\"model predictions\",outputs)\n",
    "#     nparray = outputs.cpu().numpy()  # Move tensor to CPU before conversion\n",
    "# #     if nparray[0]<0.5 and nparray[0]>-0.5:\n",
    "# #         nparray[0]=0\n",
    "# #     if nparray[0]>0.5:\n",
    "# #         nparray[0]=1\n",
    "# #     if nparray[0]<-0.5:\n",
    "# #         nparray[0]=-1\n",
    "    \n",
    "# #     print(\"one hot encoding\",nparray.size)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "obf7QfWYOBFT"
   },
   "outputs": [],
   "source": [
    "# net = ResNet50(10).to('cuda')\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=0.0001)\n",
    "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.1, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_image_path = './processed/D5/img021.jpg'\n",
    "# target_image_path= './processed/D5/target.jpg'\n",
    "\n",
    "# # Load and preprocess the images\n",
    "# target_image = load_image(target_image_path).to(device)\n",
    "# test_image = load_image(test_image_path).to(device)\n",
    "\n",
    "# # Set the model to evaluation mode\n",
    "# # model.eval()\n",
    "\n",
    "# # Disable gradient calculation\n",
    "# with torch.no_grad():\n",
    "#     # Get the model's output\n",
    "#     output = model(target_image, test_image)\n",
    "\n",
    "# # Print the output\n",
    "# print('Model Output:', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Sp3I3vApPK2w",
    "outputId": "60d8be96-76cf-4ca8-8451-9ef862d1ef19"
   },
   "outputs": [],
   "source": [
    "# EPOCHS = 30\n",
    "# for epoch in range(EPOCHS):\n",
    "#     model.train()\n",
    "#     running_loss = 0.0\n",
    "#     for i, (inputs, labels) in enumerate(train_loader):\n",
    "#         (target_images, X2_images), labels = inputs, labels\n",
    "#         target_images, X2_images, labels = target_images.to(device), X2_images.to(device), labels.to(device)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(target_images, X2_images)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         running_loss += loss.item()\n",
    "        \n",
    "#         if i % 10 == 0 and i > 0:\n",
    "#             print(f'Loss [{epoch+1}, {i}](epoch, minibatch): ', running_loss / 100)\n",
    "#             running_loss = 0.0\n",
    "\n",
    "# print('Training Done')\n",
    "\n",
    "# # Validation loop\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for data in val_loader:\n",
    "#         (target_images, X2_images), labels = data\n",
    "#         target_images, X2_images, labels = target_images.to(device), X2_images.to(device), labels.to(device)\n",
    "#         outputs = model(target_images, X2_images)\n",
    "\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print('Accuracy on validation dataset: ', 100 * (correct / total), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_image_path= './processed/D4/img001.jpg'\n",
    "\n",
    "\n",
    "# def preprocess_input_img(test_image_path):\n",
    "#     '''\n",
    "#     This function takes the path to the input test image\n",
    "#     and returns a preprocessed image (which can be used as a input to the model)\n",
    "#     (Input): Single test image path\n",
    "#     (Output): Preprocessed image\n",
    "#     '''\n",
    "\n",
    "#     # Read the original test image\n",
    "#     orig_sample_test_img = cv2.cvtColor(cv2.imread(test_image_path), cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "#     x = 50\n",
    "#     y = 0\n",
    "#     width = 200\n",
    "#     height = 200\n",
    "\n",
    "# # Crop the image\n",
    "#     orig_sample_test_img = orig_sample_test_img[y:y+height, x:x+width]\n",
    "\n",
    "\n",
    "#     # Convert image to gray scale\n",
    "#     gray_sample_test_img = cv2.cvtColor(orig_sample_test_img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "#     # Resizing image to desired input size\n",
    "#     gray_resized_test_img = cv2.resize(gray_sample_test_img, (285, 285),\n",
    "#                         interpolation = cv2.INTER_AREA)   # To shrink an image\n",
    "\n",
    "#     # Remove blemishes from image (if any)\n",
    "#     (thresh, black_n_white_sample_img) = cv2.threshold(gray_resized_test_img, 70,255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "#     # Display Images\t: Plot Sample Input and Preprocessed Test Image\n",
    "\n",
    "#     f = plt.figure(figsize=(10,5))\n",
    "#     ax1 = f.add_subplot(121)\n",
    "#     ax2 = f.add_subplot(122)\n",
    "\n",
    "#     ax1.imshow(np.squeeze(orig_sample_test_img), cmap='gray')\n",
    "#     ax1.set_title(\"Original Test Input Image\", pad=15, fontsize=13, fontweight='bold')\n",
    "#     ax2.imshow(np.squeeze(black_n_white_sample_img), cmap='gray')\n",
    "#     ax2.set_title(\"Preprocessed Test Input Image\", pad=15, fontsize=13, fontweight='bold')\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "#     return orig_sample_test_img, black_n_white_sample_img\n",
    "\n",
    "\n",
    "# x,y = preprocess_input_img(target_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "CIFAR10-ResNet50_85%.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
